{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "from skimage.filters.rank import entropy\n",
    "from skimage.morphology import disk\n",
    "import hdbscan\n",
    "\n",
    "from typing import Iterator, Tuple, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/kirb/Downloads/Volkswagen.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(path: str):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            yield frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6c8ec8a7ed41039280998cde731eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2571 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fcaee24c4743d29bbc43640feb8f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/531 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.868627786636353s\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "\n",
    "images = get_images(path)\n",
    "res = []\n",
    "change_images = []\n",
    "img_prev = None\n",
    "for n, img in enumerate(tqdm(images, total=2571)):    \n",
    "    if img_prev is not None:\n",
    "        diff = (img - img_prev)\n",
    "        diff = np.abs(diff)\n",
    "        mean_diff = diff.mean() \n",
    "        res.append(mean_diff)\n",
    "        if mean_diff > 100:\n",
    "            img = img[:, :, ::-1]\n",
    "            change_images.append(Image.fromarray(img))\n",
    "    img_prev = img\n",
    "    if n >= 2571:\n",
    "        break\n",
    "        \n",
    "dir_path = \"/tmp/dataset/prev_res/\"\n",
    "os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "for i, img in enumerate(tqdm(change_images)):\n",
    "    img.save(\"{}/{:06d}.jpg\".format(dir_path, i))\n",
    "    \n",
    "toc = time()\n",
    "print(f'time: {toc - tic}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame:\n",
    "    def __init__(self, frame: np.ndarray, frame_number: int, sum_abs_diff: np.ndarray):\n",
    "        self.frame = frame\n",
    "        self.frame_number = frame_number\n",
    "        self.sum_abs_diff = sum_abs_diff\n",
    "\n",
    "\n",
    "class FrameExtractor(object):\n",
    "    def __init__(self, use_local_maxima: bool, len_window: int, max_frames_in_chunk: int, window_type: str):\n",
    "        self.use_local_maxima = use_local_maxima\n",
    "        self.len_window = len_window\n",
    "        self.max_frames_in_chunk = max_frames_in_chunk\n",
    "        self.window_type = window_type\n",
    "\n",
    "    @staticmethod\n",
    "    def __calculate_frame_difference(frame: np.ndarray, curr_frame: np.ndarray, prev_frame: np.ndarray, frame_number: int) -> Optional[Frame]:\n",
    "        if curr_frame is None or prev_frame is None:\n",
    "            return None\n",
    "        diff = cv2.absdiff(curr_frame, prev_frame)\n",
    "        abs_diff = np.sum(diff)\n",
    "        frame = Frame(frame, frame_number, abs_diff)\n",
    "        return frame\n",
    "\n",
    "    def __process_frame(self, frame: np.ndarray, prev_frame: np.ndarray, frame_diffs: list, frames: list, frame_number: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        curr_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        frame = self.__calculate_frame_difference(frame, curr_frame, prev_frame, frame_number)\n",
    "        if frame is not None:\n",
    "            frame_diffs.append(frame.sum_abs_diff)\n",
    "            frames.append(frame)\n",
    "        prev_frame = curr_frame\n",
    "        return prev_frame, curr_frame\n",
    "\n",
    "    def __extract_all_frames_from_video(self, cap: cv2.VideoCapture) -> Iterator[Tuple[List[np.ndarray], List[int]]]:\n",
    "        curr_frame = None\n",
    "        prev_frame = None\n",
    "        frame_number = 0\n",
    "        while cap.isOpened():\n",
    "            frame_diffs = []\n",
    "            frames = []\n",
    "            for _ in range(self.max_frames_in_chunk):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    cap.release()\n",
    "                    break\n",
    "                prev_frame, curr_frame = self.__process_frame(frame, prev_frame, frame_diffs, frames, frame_number)\n",
    "                frame_number += 1\n",
    "            yield frames, frame_diffs\n",
    "\n",
    "    def __get_frames_in_local_maxima(self, frames: list, frame_diffs: list) -> Tuple[List[np.ndarray], List[int]]:\n",
    "        extracted_key_frames = []\n",
    "        extracted_key_numbers = []\n",
    "        diff_array = np.array(frame_diffs)\n",
    "        sm_diff_array = self.__smooth(diff_array, self.len_window, self.window_type)\n",
    "        frame_indexes = np.asarray(argrelextrema(sm_diff_array, np.greater))[0]\n",
    "\n",
    "        for frame_index in frame_indexes:\n",
    "            extracted_key_frames.append(frames[frame_index - 1].frame)\n",
    "            extracted_key_numbers.append(frames[frame_index - 1].frame_number)\n",
    "        return extracted_key_frames, extracted_key_numbers\n",
    "\n",
    "    @staticmethod\n",
    "    def __smooth(x: np.ndarray, window_len: int, window: str) -> np.ndarray:\n",
    "        if x.ndim != 1:\n",
    "            raise (ValueError, \"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "        if x.size < window_len:\n",
    "            raise (ValueError, \"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "        if window_len < 3:\n",
    "            return x\n",
    "\n",
    "        if window not in [\"flat\", \"hanning\", \"hamming\", \"bartlett\", \"blackman\"]:\n",
    "            raise (\n",
    "                ValueError,\n",
    "                \"Smoothing Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\",\n",
    "            )\n",
    "        s = np.r_[2 * x[0] - x[window_len:1:-1], x, 2 * x[-1] - x[-1:-window_len:-1]]\n",
    "\n",
    "        if window == \"flat\":\n",
    "            w = np.ones(window_len, \"d\")\n",
    "        else:\n",
    "            w = getattr(np, window)(window_len)\n",
    "        y = np.convolve(w / w.sum(), s, mode=\"same\")\n",
    "        return y[window_len - 1: -window_len + 1]\n",
    "\n",
    "    def extract_candidate_frames(self, cap: cv2.VideoCapture) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        extracted_candidate_key_frames = []\n",
    "        extracted_candidate_key_numbers = []\n",
    "\n",
    "        frame_extractor_from_video_generator = self.__extract_all_frames_from_video(cap)\n",
    "\n",
    "        for frames, frame_diffs in frame_extractor_from_video_generator:\n",
    "            extracted_candidate_key_frames_chunk = []\n",
    "            extracted_candidate_key_numbers_chunk = []\n",
    "            if self.use_local_maxima:\n",
    "                extracted_candidate_key_frames_chunk, extracted_candidate_key_numbers_chunk = self.__get_frames_in_local_maxima(frames, frame_diffs)\n",
    "                extracted_candidate_key_frames.extend(extracted_candidate_key_frames_chunk)\n",
    "                extracted_candidate_key_numbers.extend(extracted_candidate_key_numbers_chunk)\n",
    "\n",
    "        extracted_candidate_key_frames = np.array(extracted_candidate_key_frames)\n",
    "        extracted_candidate_key_numbers = np.array(extracted_candidate_key_numbers)\n",
    "        return extracted_candidate_key_frames, extracted_candidate_key_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSelector(object):\n",
    "    def __init__(self, min_brightness_value: float, max_brightness_value: float, min_contrast_value: float, max_contrast_value: float):\n",
    "        self.min_brightness_value = min_brightness_value\n",
    "        self.max_brightness_value = max_brightness_value\n",
    "\n",
    "        self.min_contrast_value = min_contrast_value\n",
    "        self.max_contrast_value = max_contrast_value\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_brightness_and_contrast_score(images: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        gray = np.average(images, axis=-1, weights=[0.114, 0.587, 0.299])\n",
    "        brightness_score = np.average(gray, axis=(1, 2)) * 100 / 255\n",
    "        contrast_score = np.std(gray, axis=(1, 2)) * 100 / 255\n",
    "\n",
    "        return brightness_score, contrast_score\n",
    "\n",
    "    def __filter_optimum_brightness_and_contrast_images(self, input_img_files: np.ndarray, input_img_numbers: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        brightness_score, contrast_score = self.__get_brightness_and_contrast_score(input_img_files)\n",
    "        brightness_contrast_ok = (brightness_score > self.min_brightness_value) & (brightness_score < self.max_brightness_value) &\\\n",
    "                                 (contrast_score > self.min_contrast_value) & (contrast_score < self.max_contrast_value)\n",
    "\n",
    "        return input_img_files[brightness_contrast_ok], input_img_numbers[brightness_contrast_ok]\n",
    "\n",
    "    @staticmethod\n",
    "    def __prepare_cluster_sets__hdbscan(files: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        all_dst = []\n",
    "        for img_file in files:\n",
    "            img = cv2.cvtColor(img_file, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (256, 256), img)\n",
    "            imf = np.float32(img) / 255.0\n",
    "            dst = cv2.dct(imf)\n",
    "            dst = dst[:16, :16]\n",
    "            dst = dst.reshape(256)\n",
    "            all_dst.append(dst)\n",
    "\n",
    "        Hdbscan = hdbscan.HDBSCAN(min_cluster_size=2, metric='manhattan').fit(all_dst)\n",
    "        labels = np.add(Hdbscan.labels_, 1)\n",
    "        nb_clusters = len(np.unique(Hdbscan.labels_))\n",
    "\n",
    "        files_clusters_index_array = []\n",
    "        files_clusters_index_array_of_only_one_image = [np.where(labels == 0)]\n",
    "\n",
    "        for i in np.arange(1, nb_clusters):\n",
    "            files_clusters_index_array.append(np.where(labels == i))\n",
    "\n",
    "        files_clusters_index_array = np.array(files_clusters_index_array)\n",
    "        files_clusters_index_array_of_only_one_image = np.array(files_clusters_index_array_of_only_one_image)\n",
    "        return files_clusters_index_array, files_clusters_index_array_of_only_one_image\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_laplacian_scores(files: np.ndarray, n_images: np.ndarray) -> List[float]:\n",
    "        variance_laplacians = []\n",
    "        for image_i in n_images:\n",
    "            img_file = files[n_images[image_i]]\n",
    "            img = cv2.cvtColor(img_file, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            variance_laplacian = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "            variance_laplacians.append(variance_laplacian)\n",
    "\n",
    "        return variance_laplacians\n",
    "\n",
    "    def __get_best_images_index_from_each_cluster(self, files: np.ndarray, files_clusters_index_array: np.ndarray) -> List[int]:\n",
    "        filtered_items = []\n",
    "\n",
    "        clusters = np.arange(len(files_clusters_index_array))\n",
    "        for cluster_i in clusters:\n",
    "            curr_row = files_clusters_index_array[cluster_i][0]\n",
    "            n_images = np.arange(len(curr_row))\n",
    "            variance_laplacians = self.__get_laplacian_scores(files, n_images)\n",
    "            selected_frame_of_current_cluster = curr_row[np.argmax(variance_laplacians)]\n",
    "            filtered_items.append(selected_frame_of_current_cluster)\n",
    "\n",
    "        return filtered_items\n",
    "\n",
    "    def select_best_frames(self, input_key_frames: np.ndarray, input_key_numbers: np.ndarray) -> Tuple[List[np.ndarray], List[int]]:\n",
    "        filtered_images_list = []\n",
    "        filtered_numbers_list = []\n",
    "        input_key_frames, input_key_numbers = self.__filter_optimum_brightness_and_contrast_images(input_key_frames, input_key_numbers)\n",
    "\n",
    "        if len(input_key_frames) >= 1:\n",
    "            files_clusters_index_array, files_clusters_index_array_of_only_one_image = self.__prepare_cluster_sets__hdbscan(input_key_frames)\n",
    "            selected_images_index = self.__get_best_images_index_from_each_cluster(input_key_frames, files_clusters_index_array)\n",
    "            files_clusters_index_array_of_only_one_image = [item for t in files_clusters_index_array_of_only_one_image for item in t]\n",
    "            files_clusters_index_array_of_only_one_image = files_clusters_index_array_of_only_one_image[0].tolist()\n",
    "            selected_images_index.extend(files_clusters_index_array_of_only_one_image)\n",
    "            for index in selected_images_index:\n",
    "                img = input_key_frames[index]\n",
    "                number = input_key_numbers[index]\n",
    "                filtered_images_list.append(img)\n",
    "                filtered_numbers_list.append(number)\n",
    "\n",
    "        return filtered_images_list, filtered_numbers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-f09b044861e3>:196: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  files_clusters_index_array = np.array(files_clusters_index_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.397907495498657s\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "\n",
    "vd = FrameExtractor()\n",
    "imgs = vd.extract_candidate_frames(path)\n",
    "\n",
    "dir_new_path = \"/tmp/dataset/no_smooth_no_brightness_res/\"\n",
    "os.makedirs(dir_new_path, exist_ok=True)\n",
    "\n",
    "config = Configs()\n",
    "pool_obj = Pool(processes=cpu_count())\n",
    "\n",
    "final_images = ImageSelector(pool_obj)\n",
    "imgs_final = final_images.select_best_frames(imgs, dir_new_path)\n",
    "\n",
    "for counter, i in enumerate(imgs_final):\n",
    "    vd.save_frame_to_disk(\n",
    "        i,\n",
    "        file_path=os.path.join(dir_new_path),\n",
    "        file_name=\"test_\" + str(counter),\n",
    "        file_ext=\".jpeg\",\n",
    "    )\n",
    "    \n",
    "toc = time()\n",
    "print(f'time: {toc - tic}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a93b16b85909>:196: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  files_clusters_index_array = np.array(files_clusters_index_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 267.0932261943817s\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "\n",
    "vd = FrameExtractor()\n",
    "imgs = vd.extract_candidate_frames(path)\n",
    "\n",
    "dir_new_path = \"/tmp/dataset/no_smooth_res/\"\n",
    "os.makedirs(dir_new_path, exist_ok=True)\n",
    "\n",
    "config = Configs()\n",
    "pool_obj = Pool(processes=cpu_count())\n",
    "\n",
    "final_images = ImageSelector(pool_obj)\n",
    "imgs_final = final_images.select_best_frames(imgs, dir_new_path)\n",
    "\n",
    "for counter, i in enumerate(imgs_final):\n",
    "    vd.save_frame_to_disk(\n",
    "        i,\n",
    "        file_path=os.path.join(dir_new_path),\n",
    "        file_name=\"test_\" + str(counter),\n",
    "        file_ext=\".jpeg\",\n",
    "    )\n",
    "    \n",
    "toc = time()\n",
    "print(f'time: {toc - tic}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a93b16b85909>:196: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  files_clusters_index_array = np.array(files_clusters_index_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 75.28714036941528s\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "\n",
    "vd = FrameExtractor()\n",
    "imgs = vd.extract_candidate_frames(path)\n",
    "\n",
    "dir_new_path = \"/tmp/dataset/all_in_res/\"\n",
    "os.makedirs(dir_new_path, exist_ok=True)\n",
    "\n",
    "config = Configs()\n",
    "pool_obj = Pool(processes=cpu_count())\n",
    "\n",
    "final_images = ImageSelector(pool_obj)\n",
    "imgs_final = final_images.select_best_frames(imgs, dir_new_path)\n",
    "\n",
    "for counter, i in enumerate(imgs_final):\n",
    "    vd.save_frame_to_disk(\n",
    "        i,\n",
    "        file_path=os.path.join(dir_new_path),\n",
    "        file_name=\"test_\" + str(counter),\n",
    "        file_ext=\".jpeg\",\n",
    "    )\n",
    "    \n",
    "toc = time()\n",
    "print(f'time: {toc - tic}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-631b4fe98bf0>:196: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  files_clusters_index_array = np.array(files_clusters_index_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.274819135665894s\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "\n",
    "vd = FrameExtractor()\n",
    "imgs = vd.extract_candidate_frames(path)\n",
    "\n",
    "dir_new_path = \"/tmp/dataset/no_brightness_res/\"\n",
    "os.makedirs(dir_new_path, exist_ok=True)\n",
    "\n",
    "config = Configs()\n",
    "pool_obj = Pool(processes=cpu_count())\n",
    "\n",
    "final_images = ImageSelector(pool_obj)\n",
    "imgs_final = final_images.select_best_frames(imgs, dir_new_path)\n",
    "\n",
    "for counter, i in enumerate(imgs_final):\n",
    "    vd.save_frame_to_disk(\n",
    "        i,\n",
    "        file_path=os.path.join(dir_new_path),\n",
    "        file_name=\"test_\" + str(counter),\n",
    "        file_ext=\".jpeg\",\n",
    "    )\n",
    "    \n",
    "toc = time()\n",
    "print(f'time: {toc - tic}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-0280b949d6e4>:196: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  files_clusters_index_array = np.array(files_clusters_index_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 140.90563869476318s\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "\n",
    "vd = FrameExtractor()\n",
    "imgs = vd.extract_candidate_frames(path)\n",
    "\n",
    "#dir_new_path = \"/tmp/dataset/all_in_res/\"\n",
    "#os.makedirs(dir_new_path, exist_ok=True)\n",
    "\n",
    "config = Configs()\n",
    "pool_obj = Pool(processes=cpu_count())\n",
    "\n",
    "final_images = ImageSelector(pool_obj)\n",
    "imgs_final = final_images.select_best_frames(imgs, dir_new_path)\n",
    "\n",
    "'''for counter, i in enumerate(imgs_final):\n",
    "    vd.save_frame_to_disk(\n",
    "        i,\n",
    "        file_path=os.path.join(dir_new_path),\n",
    "        file_name=\"test_\" + str(counter),\n",
    "        file_ext=\".jpeg\",\n",
    "    )'''\n",
    "    \n",
    "toc = time()\n",
    "print(f'time: {toc - tic}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-60cfc1de3ab7>:169: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  files_clusters_index_array = np.array(files_clusters_index_array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.108604192733765s\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "\n",
    "vd = FrameExtractor()\n",
    "imgs = vd.extract_candidate_frames(path)\n",
    "\n",
    "dir_new_path = \"/tmp/dataset/all_new_in_res/\"\n",
    "os.makedirs(dir_new_path, exist_ok=True)\n",
    "\n",
    "config = Configs()\n",
    "pool_obj = Pool(processes=cpu_count())\n",
    "\n",
    "final_images = ImageSelector(pool_obj)\n",
    "imgs_final = final_images.select_best_frames(imgs, dir_new_path)\n",
    "\n",
    "for counter, i in enumerate(imgs_final):\n",
    "    vd.save_frame_to_disk(\n",
    "        i,\n",
    "        file_path=os.path.join(dir_new_path),\n",
    "        file_name=\"test_\" + str(counter),\n",
    "        file_ext=\".jpeg\",\n",
    "    )\n",
    "    \n",
    "toc = time()\n",
    "print(f'time: {toc - tic}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = FrameExtractor(True, 10, 2500, \"hanning\")\n",
    "imgs, numbers = vd.extract_candidate_frames(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-60-ace942191b71>:46: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  files_clusters_index_array = np.array(files_clusters_index_array)\n"
     ]
    }
   ],
   "source": [
    "ims = ImageSelector(15.0, 85.0, 10.0, 90.0)\n",
    "imgs_final, numbers_final = ims.select_best_frames(imgs, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_new_path = \"/tmp/dataset/all_new_in_res/\"\n",
    "os.makedirs(dir_new_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FrameExtractor' object has no attribute 'save_frame_to_disk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-ba2930935a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     vd.save_frame_to_disk(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_new_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FrameExtractor' object has no attribute 'save_frame_to_disk'"
     ]
    }
   ],
   "source": [
    "for counter, i in enumerate(imgs_final):\n",
    "    vd.save_frame_to_disk(\n",
    "        i,\n",
    "        file_path=os.path.join(dir_new_path),\n",
    "        file_name=\"test_\" + str(counter),\n",
    "        file_ext=\".jpeg\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
